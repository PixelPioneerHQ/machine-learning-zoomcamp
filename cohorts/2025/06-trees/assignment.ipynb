{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cac9ee",
   "metadata": {},
   "source": [
    "# Module 6 ? Trees Homework (2025)\n",
    "\n",
    "This notebook follows the HW06 brief end?to?end and prints the values you need to map to the multiple?choice questions. Each section explains the steps and why the results make sense.\n",
    "\n",
    "Dataset: car fuel efficiency (target: `fuel_efficiency_mpg`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b030dc",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255c64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.6f}')\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fa1d44",
   "metadata": {},
   "source": [
    "## 2. Load dataset\n",
    "\n",
    "Source URL is provided by the course. If the download fails (e.g., due to network restrictions), save it under `data/car_fuel_efficiency.csv` and replace the URL below with the local path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e010d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>num_cylinders</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>vehicle_weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>drivetrain</th>\n",
       "      <th>num_doors</th>\n",
       "      <th>fuel_efficiency_mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>3413.433759</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>2003</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>All-wheel drive</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.231729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3149.664934</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>2007</td>\n",
       "      <td>USA</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Front-wheel drive</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.688217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>3079.038997</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>2018</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>Front-wheel drive</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.246341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2542.392402</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>2009</td>\n",
       "      <td>USA</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>All-wheel drive</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.912736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>3460.870990</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>2009</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>All-wheel drive</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.488369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_displacement  num_cylinders  horsepower  vehicle_weight  \\\n",
       "0                  170       3.000000  159.000000     3413.433759   \n",
       "1                  130       5.000000   97.000000     3149.664934   \n",
       "2                  170            NaN   78.000000     3079.038997   \n",
       "3                  220       4.000000         NaN     2542.392402   \n",
       "4                  210       1.000000  140.000000     3460.870990   \n",
       "\n",
       "   acceleration  model_year  origin fuel_type         drivetrain  num_doors  \\\n",
       "0     17.700000        2003  Europe  Gasoline    All-wheel drive   0.000000   \n",
       "1     17.800000        2007     USA  Gasoline  Front-wheel drive   0.000000   \n",
       "2     15.100000        2018  Europe  Gasoline  Front-wheel drive   0.000000   \n",
       "3     20.200000        2009     USA    Diesel    All-wheel drive   2.000000   \n",
       "4     14.400000        2009  Europe  Gasoline    All-wheel drive   2.000000   \n",
       "\n",
       "   fuel_efficiency_mpg  \n",
       "0            13.231729  \n",
       "1            13.688217  \n",
       "2            14.246341  \n",
       "3            16.912736  \n",
       "4            12.488369  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv'\n",
    "cols = [\n",
    "    'engine_displacement','num_cylinders','horsepower','vehicle_weight','acceleration',\n",
    "    'model_year','origin','fuel_type','drivetrain','num_doors','fuel_efficiency_mpg'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(URL, usecols=cols)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca646974",
   "metadata": {},
   "source": [
    "## 3. Preparation\n",
    "\n",
    "- Fill missing values in numeric features with 0.0 (keeps scale for trees).\n",
    "- Fill missing categorical values with 'NA'.\n",
    "- Split train/val/test: 60/20/20 with `random_state=1`.\n",
    "- Convert to dictionaries and then to sparse matrices via `DictVectorizer(sparse=True)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62fead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " array(['acceleration', 'drivetrain=All-wheel drive',\n",
       "        'drivetrain=Front-wheel drive', 'engine_displacement',\n",
       "        'fuel_type=Diesel', 'fuel_type=Gasoline', 'horsepower',\n",
       "        'model_year', 'num_cylinders', 'num_doors'], dtype=object))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'fuel_efficiency_mpg'\n",
    "features = [c for c in df.columns if c != target]\n",
    "\n",
    "num_cols = [c for c in features if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in features if c not in num_cols]\n",
    "\n",
    "# Impute\n",
    "X_df = df[features].copy()\n",
    "for c in num_cols:\n",
    "    X_df[c] = X_df[c].astype('float64').fillna(0.0)\n",
    "for c in cat_cols:\n",
    "    X_df[c] = X_df[c].astype('object').fillna('NA')\n",
    "\n",
    "y = df[target].values\n",
    "\n",
    "# Split 60/20/20\n",
    "X_train_df, X_temp_df, y_train, y_temp = train_test_split(\n",
    "    X_df, y, test_size=0.4, random_state=1\n",
    ")\n",
    "X_val_df, X_test_df, y_val, y_test = train_test_split(\n",
    "    X_temp_df, y_temp, test_size=0.5, random_state=1\n",
    ")\n",
    "\n",
    "# DictVectorizer sparse\n",
    "train_dicts = X_train_df.to_dict(orient='records')\n",
    "val_dicts = X_val_df.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "feature_names = dv.get_feature_names_out()\n",
    "len(feature_names), feature_names[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2745d8",
   "metadata": {},
   "source": [
    "## 4. Q1 ? Decision Tree (max_depth=1)\n",
    "We fit a depth?1 tree and inspect the root split feature (node 0). For one?hot encoded categoricals, we map `feature_name` like `origin=Asia` to its base feature `origin`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29223f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vehicle_weight', 'vehicle_weight')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Root node feature index\n",
    "root_idx = int(tree.tree_.feature[0])\n",
    "root_name = feature_names[root_idx]\n",
    "base_name = root_name.split('=')[0]\n",
    "root_name, base_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45933358",
   "metadata": {},
   "source": [
    "The base feature identifies which column the root split uses, even if the actual split is on a specific category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c5014",
   "metadata": {},
   "source": [
    "## 5. Q2 ? Random Forest (10 trees)\n",
    "Train a small forest with `n_estimators=10` and evaluate RMSE on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1952f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4602815367032658, 0.46)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf10 = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf10.fit(X_train, y_train)\n",
    "val_pred10 = rf10.predict(X_val)\n",
    "rmse_rf10 = rmse(y_val, val_pred10)\n",
    "rmse_rf10, round(rmse_rf10, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059950fc",
   "metadata": {},
   "source": [
    "## 6. Q3 ? When does RMSE stop improving (by 3 decimals)?\n",
    "We scan `n_estimators` from 10 to 200 (step 10), keep the best (rounded to 3 decimals), and report the last `n` where a new best appears. If improvement continues to 200, we answer 200.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a29ec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(10, 0.4602815367032659),\n",
       "  (20, 0.4461567458911003),\n",
       "  (30, 0.4397780761280069),\n",
       "  (40, 0.4383939265191819),\n",
       "  (50, 0.4371703249467452)],\n",
       " 0.435,\n",
       " 90)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = list(range(10, 201, 10))\n",
    "rmse_track = []\n",
    "best = None\n",
    "last_new_best_n = None\n",
    "\n",
    "for n in ns:\n",
    "    m = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    m.fit(X_train, y_train)\n",
    "    p = m.predict(X_val)\n",
    "    r = rmse(y_val, p)\n",
    "    rmse_track.append((n, r))\n",
    "    r3 = round(r, 3)\n",
    "    if best is None or r3 < best:\n",
    "        best = r3\n",
    "        last_new_best_n = n\n",
    "\n",
    "rmse_track[:5], best, last_new_best_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29b2dd",
   "metadata": {},
   "source": [
    "The `last_new_best_n` value is the answer for Q3 (considering 3 decimal places).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da57ca8",
   "metadata": {},
   "source": [
    "## 7. Q4 ? Best max_depth by mean RMSE\n",
    "For each depth in `[10, 15, 20, 25]`, compute RMSE across `n_estimators` ? {10,20,...,200} and take the mean. Select the depth with the lowest mean RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f84b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({10: 0.43624733022811624,\n",
       "  15: 0.4378245115127723,\n",
       "  20: 0.43769343549884143,\n",
       "  25: 0.43765343428485853},\n",
       " 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths = [10, 15, 20, 25]\n",
    "mean_rmse = {}\n",
    "for d in depths:\n",
    "    rs = []\n",
    "    for n in ns:\n",
    "        m = RandomForestRegressor(n_estimators=n, max_depth=d, random_state=1, n_jobs=-1)\n",
    "        m.fit(X_train, y_train)\n",
    "        p = m.predict(X_val)\n",
    "        rs.append(rmse(y_val, p))\n",
    "    mean_rmse[d] = float(np.mean(rs))\n",
    "\n",
    "mean_rmse, min(mean_rmse, key=mean_rmse.get)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f813c",
   "metadata": {},
   "source": [
    "## 8. Q5 ? Feature importances (RF)\n",
    "Train RF with `n_estimators=10, max_depth=20` and inspect `feature_importances_`. We aggregate importances per original numeric feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e3f26df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'vehicle_weight': 0.9598782143148441,\n",
       "  'horsepower': 0.01593348148976617,\n",
       "  'acceleration': 0.01144231373523756,\n",
       "  'engine_displacement': 0.0031594240303503144},\n",
       " 'vehicle_weight')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_imp = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf_imp.fit(X_train, y_train)\n",
    "imp = rf_imp.feature_importances_\n",
    "\n",
    "# Aggregate by base feature (important for categoricals with one-hot; numeric are one column)\n",
    "from collections import defaultdict\n",
    "agg = defaultdict(float)\n",
    "for name, w in zip(feature_names, imp):\n",
    "    base = name.split('=')[0]\n",
    "    agg[base] += float(w)\n",
    "\n",
    "candidates = ['vehicle_weight','horsepower','acceleration','engine_displacement']\n",
    "subset = {k: agg.get(k, 0.0) for k in candidates}\n",
    "subset, max(subset, key=subset.get)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfe4f9",
   "metadata": {},
   "source": [
    "## 9. Q6 ? XGBoost (eta tuning)\n",
    "We compare `eta=0.3` vs `eta=0.1` for 100 boosting rounds.\n",
    "\n",
    "Install and train:\n",
    "```bash\n",
    "pip install xgboost\n",
    "```\n",
    "If installation is blocked, skip execution and answer later; otherwise run the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01d55ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost not available or failed to run: Expecting a sequence of strings for feature names, got: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# If xgboost is unavailable, skip this cell gracefully\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_names)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val, feature_names=feature_names)\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "    def run_xgb(eta):\n",
    "        params = {\n",
    "            'eta': eta,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 1,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'nthread': 8,\n",
    "            'seed': 1,\n",
    "            'verbosity': 0,\n",
    "        }\n",
    "        model = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist)\n",
    "        val_pred = model.predict(dval)\n",
    "        return rmse(y_val, val_pred)\n",
    "\n",
    "    rmse_03 = run_xgb(0.3)\n",
    "    rmse_01 = run_xgb(0.1)\n",
    "\n",
    "    (round(rmse_03, 3), round(rmse_01, 3)), ('0.3' if rmse_03 < rmse_01 else '0.1' if rmse_01 < rmse_03 else 'equal')\n",
    "except Exception as e:\n",
    "    print('xgboost not available or failed to run:', e)\n",
    "    rmse_03 = rmse_01 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62f15e93-3037-49c0-afe9-c18c4d7b3134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.83282\tval-rmse:1.82567\n",
      "[1]\ttrain-rmse:1.33231\tval-rmse:1.32771\n",
      "[2]\ttrain-rmse:0.99034\tval-rmse:0.99257\n",
      "[3]\ttrain-rmse:0.76090\tval-rmse:0.76897\n",
      "[4]\ttrain-rmse:0.61110\tval-rmse:0.62742\n",
      "[5]\ttrain-rmse:0.51643\tval-rmse:0.54010\n",
      "[6]\ttrain-rmse:0.45800\tval-rmse:0.48954\n",
      "[7]\ttrain-rmse:0.42172\tval-rmse:0.46026\n",
      "[8]\ttrain-rmse:0.39836\tval-rmse:0.44332\n",
      "[9]\ttrain-rmse:0.38494\tval-rmse:0.43456\n",
      "[10]\ttrain-rmse:0.37400\tval-rmse:0.43004\n",
      "[11]\ttrain-rmse:0.36596\tval-rmse:0.42696\n",
      "[12]\ttrain-rmse:0.36050\tval-rmse:0.42569\n",
      "[13]\ttrain-rmse:0.35549\tval-rmse:0.42519\n",
      "[14]\ttrain-rmse:0.35143\tval-rmse:0.42455\n",
      "[15]\ttrain-rmse:0.34792\tval-rmse:0.42450\n",
      "[16]\ttrain-rmse:0.34533\tval-rmse:0.42478\n",
      "[17]\ttrain-rmse:0.34356\tval-rmse:0.42472\n",
      "[18]\ttrain-rmse:0.34129\tval-rmse:0.42472\n",
      "[19]\ttrain-rmse:0.33846\tval-rmse:0.42502\n",
      "[20]\ttrain-rmse:0.33724\tval-rmse:0.42509\n",
      "[21]\ttrain-rmse:0.33463\tval-rmse:0.42538\n",
      "[22]\ttrain-rmse:0.33260\tval-rmse:0.42543\n",
      "[23]\ttrain-rmse:0.33023\tval-rmse:0.42611\n",
      "[24]\ttrain-rmse:0.32738\tval-rmse:0.42648\n",
      "[25]\ttrain-rmse:0.32515\tval-rmse:0.42667\n",
      "[26]\ttrain-rmse:0.32413\tval-rmse:0.42667\n",
      "[27]\ttrain-rmse:0.32307\tval-rmse:0.42684\n",
      "[28]\ttrain-rmse:0.32065\tval-rmse:0.42737\n",
      "[29]\ttrain-rmse:0.31898\tval-rmse:0.42750\n",
      "[30]\ttrain-rmse:0.31757\tval-rmse:0.42754\n",
      "[31]\ttrain-rmse:0.31658\tval-rmse:0.42764\n",
      "[32]\ttrain-rmse:0.31502\tval-rmse:0.42733\n",
      "[33]\ttrain-rmse:0.31278\tval-rmse:0.42747\n",
      "[34]\ttrain-rmse:0.30976\tval-rmse:0.42850\n",
      "[35]\ttrain-rmse:0.30703\tval-rmse:0.42903\n",
      "[36]\ttrain-rmse:0.30576\tval-rmse:0.42988\n",
      "[37]\ttrain-rmse:0.30363\tval-rmse:0.43015\n",
      "[38]\ttrain-rmse:0.30210\tval-rmse:0.42994\n",
      "[39]\ttrain-rmse:0.30063\tval-rmse:0.43045\n",
      "[40]\ttrain-rmse:0.29886\tval-rmse:0.43086\n",
      "[41]\ttrain-rmse:0.29731\tval-rmse:0.43142\n",
      "[42]\ttrain-rmse:0.29624\tval-rmse:0.43135\n",
      "[43]\ttrain-rmse:0.29365\tval-rmse:0.43230\n",
      "[44]\ttrain-rmse:0.29186\tval-rmse:0.43204\n",
      "[45]\ttrain-rmse:0.28934\tval-rmse:0.43245\n",
      "[46]\ttrain-rmse:0.28795\tval-rmse:0.43241\n",
      "[47]\ttrain-rmse:0.28610\tval-rmse:0.43278\n",
      "[48]\ttrain-rmse:0.28531\tval-rmse:0.43327\n",
      "[49]\ttrain-rmse:0.28416\tval-rmse:0.43347\n",
      "[50]\ttrain-rmse:0.28277\tval-rmse:0.43405\n",
      "[51]\ttrain-rmse:0.28022\tval-rmse:0.43436\n",
      "[52]\ttrain-rmse:0.27782\tval-rmse:0.43439\n",
      "[53]\ttrain-rmse:0.27699\tval-rmse:0.43482\n",
      "[54]\ttrain-rmse:0.27506\tval-rmse:0.43473\n",
      "[55]\ttrain-rmse:0.27370\tval-rmse:0.43501\n",
      "[56]\ttrain-rmse:0.27255\tval-rmse:0.43501\n",
      "[57]\ttrain-rmse:0.27110\tval-rmse:0.43538\n",
      "[58]\ttrain-rmse:0.26940\tval-rmse:0.43557\n",
      "[59]\ttrain-rmse:0.26676\tval-rmse:0.43594\n",
      "[60]\ttrain-rmse:0.26525\tval-rmse:0.43583\n",
      "[61]\ttrain-rmse:0.26286\tval-rmse:0.43585\n",
      "[62]\ttrain-rmse:0.25974\tval-rmse:0.43639\n",
      "[63]\ttrain-rmse:0.25903\tval-rmse:0.43656\n",
      "[64]\ttrain-rmse:0.25800\tval-rmse:0.43643\n",
      "[65]\ttrain-rmse:0.25625\tval-rmse:0.43706\n",
      "[66]\ttrain-rmse:0.25442\tval-rmse:0.43738\n",
      "[67]\ttrain-rmse:0.25376\tval-rmse:0.43738\n",
      "[68]\ttrain-rmse:0.25297\tval-rmse:0.43739\n",
      "[69]\ttrain-rmse:0.25100\tval-rmse:0.43752\n",
      "[70]\ttrain-rmse:0.24983\tval-rmse:0.43777\n",
      "[71]\ttrain-rmse:0.24735\tval-rmse:0.43748\n",
      "[72]\ttrain-rmse:0.24598\tval-rmse:0.43722\n",
      "[73]\ttrain-rmse:0.24452\tval-rmse:0.43745\n",
      "[74]\ttrain-rmse:0.24283\tval-rmse:0.43773\n",
      "[75]\ttrain-rmse:0.24110\tval-rmse:0.43803\n",
      "[76]\ttrain-rmse:0.23907\tval-rmse:0.43844\n",
      "[77]\ttrain-rmse:0.23820\tval-rmse:0.43837\n",
      "[78]\ttrain-rmse:0.23585\tval-rmse:0.43860\n",
      "[79]\ttrain-rmse:0.23509\tval-rmse:0.43874\n",
      "[80]\ttrain-rmse:0.23379\tval-rmse:0.43902\n",
      "[81]\ttrain-rmse:0.23154\tval-rmse:0.43913\n",
      "[82]\ttrain-rmse:0.23045\tval-rmse:0.43942\n",
      "[83]\ttrain-rmse:0.23004\tval-rmse:0.43947\n",
      "[84]\ttrain-rmse:0.22986\tval-rmse:0.43969\n",
      "[85]\ttrain-rmse:0.22874\tval-rmse:0.43986\n",
      "[86]\ttrain-rmse:0.22740\tval-rmse:0.43970\n",
      "[87]\ttrain-rmse:0.22540\tval-rmse:0.43995\n",
      "[88]\ttrain-rmse:0.22300\tval-rmse:0.44101\n",
      "[89]\ttrain-rmse:0.22166\tval-rmse:0.44131\n",
      "[90]\ttrain-rmse:0.22023\tval-rmse:0.44154\n",
      "[91]\ttrain-rmse:0.21927\tval-rmse:0.44184\n",
      "[92]\ttrain-rmse:0.21791\tval-rmse:0.44189\n",
      "[93]\ttrain-rmse:0.21708\tval-rmse:0.44224\n",
      "[94]\ttrain-rmse:0.21549\tval-rmse:0.44252\n",
      "[95]\ttrain-rmse:0.21304\tval-rmse:0.44281\n",
      "[96]\ttrain-rmse:0.21101\tval-rmse:0.44336\n",
      "[97]\ttrain-rmse:0.20995\tval-rmse:0.44328\n",
      "[98]\ttrain-rmse:0.20956\tval-rmse:0.44350\n",
      "[99]\ttrain-rmse:0.20896\tval-rmse:0.44340\n",
      "[0]\ttrain-rmse:2.31334\tval-rmse:2.30592\n",
      "[1]\ttrain-rmse:2.09552\tval-rmse:2.08865\n",
      "[2]\ttrain-rmse:1.90001\tval-rmse:1.89221\n",
      "[3]\ttrain-rmse:1.72438\tval-rmse:1.71766\n",
      "[4]\ttrain-rmse:1.56719\tval-rmse:1.56150\n",
      "[5]\ttrain-rmse:1.42645\tval-rmse:1.42157\n",
      "[6]\ttrain-rmse:1.30047\tval-rmse:1.29580\n",
      "[7]\ttrain-rmse:1.18786\tval-rmse:1.18468\n",
      "[8]\ttrain-rmse:1.08744\tval-rmse:1.08657\n",
      "[9]\ttrain-rmse:0.99801\tval-rmse:0.99964\n",
      "[10]\ttrain-rmse:0.91846\tval-rmse:0.92183\n",
      "[11]\ttrain-rmse:0.84797\tval-rmse:0.85324\n",
      "[12]\ttrain-rmse:0.78540\tval-rmse:0.79241\n",
      "[13]\ttrain-rmse:0.73026\tval-rmse:0.73968\n",
      "[14]\ttrain-rmse:0.68164\tval-rmse:0.69327\n",
      "[15]\ttrain-rmse:0.63889\tval-rmse:0.65351\n",
      "[16]\ttrain-rmse:0.60130\tval-rmse:0.61854\n",
      "[17]\ttrain-rmse:0.56852\tval-rmse:0.58847\n",
      "[18]\ttrain-rmse:0.53982\tval-rmse:0.56232\n",
      "[19]\ttrain-rmse:0.51488\tval-rmse:0.53952\n",
      "[20]\ttrain-rmse:0.49316\tval-rmse:0.52039\n",
      "[21]\ttrain-rmse:0.47428\tval-rmse:0.50442\n",
      "[22]\ttrain-rmse:0.45775\tval-rmse:0.49005\n",
      "[23]\ttrain-rmse:0.44362\tval-rmse:0.47827\n",
      "[24]\ttrain-rmse:0.43128\tval-rmse:0.46892\n",
      "[25]\ttrain-rmse:0.42094\tval-rmse:0.46085\n",
      "[26]\ttrain-rmse:0.41169\tval-rmse:0.45357\n",
      "[27]\ttrain-rmse:0.40388\tval-rmse:0.44756\n",
      "[28]\ttrain-rmse:0.39696\tval-rmse:0.44256\n",
      "[29]\ttrain-rmse:0.39086\tval-rmse:0.43842\n",
      "[30]\ttrain-rmse:0.38552\tval-rmse:0.43528\n",
      "[31]\ttrain-rmse:0.38094\tval-rmse:0.43225\n",
      "[32]\ttrain-rmse:0.37679\tval-rmse:0.42949\n",
      "[33]\ttrain-rmse:0.37276\tval-rmse:0.42710\n",
      "[34]\ttrain-rmse:0.36956\tval-rmse:0.42521\n",
      "[35]\ttrain-rmse:0.36644\tval-rmse:0.42379\n",
      "[36]\ttrain-rmse:0.36394\tval-rmse:0.42255\n",
      "[37]\ttrain-rmse:0.36141\tval-rmse:0.42146\n",
      "[38]\ttrain-rmse:0.35933\tval-rmse:0.42039\n",
      "[39]\ttrain-rmse:0.35729\tval-rmse:0.41950\n",
      "[40]\ttrain-rmse:0.35546\tval-rmse:0.41889\n",
      "[41]\ttrain-rmse:0.35377\tval-rmse:0.41861\n",
      "[42]\ttrain-rmse:0.35241\tval-rmse:0.41823\n",
      "[43]\ttrain-rmse:0.35096\tval-rmse:0.41763\n",
      "[44]\ttrain-rmse:0.34967\tval-rmse:0.41721\n",
      "[45]\ttrain-rmse:0.34800\tval-rmse:0.41680\n",
      "[46]\ttrain-rmse:0.34677\tval-rmse:0.41670\n",
      "[47]\ttrain-rmse:0.34526\tval-rmse:0.41656\n",
      "[48]\ttrain-rmse:0.34369\tval-rmse:0.41644\n",
      "[49]\ttrain-rmse:0.34236\tval-rmse:0.41672\n",
      "[50]\ttrain-rmse:0.34115\tval-rmse:0.41644\n",
      "[51]\ttrain-rmse:0.34015\tval-rmse:0.41647\n",
      "[52]\ttrain-rmse:0.33910\tval-rmse:0.41630\n",
      "[53]\ttrain-rmse:0.33800\tval-rmse:0.41654\n",
      "[54]\ttrain-rmse:0.33712\tval-rmse:0.41628\n",
      "[55]\ttrain-rmse:0.33633\tval-rmse:0.41641\n",
      "[56]\ttrain-rmse:0.33544\tval-rmse:0.41633\n",
      "[57]\ttrain-rmse:0.33478\tval-rmse:0.41639\n",
      "[58]\ttrain-rmse:0.33409\tval-rmse:0.41637\n",
      "[59]\ttrain-rmse:0.33317\tval-rmse:0.41618\n",
      "[60]\ttrain-rmse:0.33254\tval-rmse:0.41610\n",
      "[61]\ttrain-rmse:0.33207\tval-rmse:0.41601\n",
      "[62]\ttrain-rmse:0.33104\tval-rmse:0.41596\n",
      "[63]\ttrain-rmse:0.33071\tval-rmse:0.41597\n",
      "[64]\ttrain-rmse:0.32943\tval-rmse:0.41593\n",
      "[65]\ttrain-rmse:0.32892\tval-rmse:0.41599\n",
      "[66]\ttrain-rmse:0.32851\tval-rmse:0.41606\n",
      "[67]\ttrain-rmse:0.32778\tval-rmse:0.41600\n",
      "[68]\ttrain-rmse:0.32748\tval-rmse:0.41591\n",
      "[69]\ttrain-rmse:0.32686\tval-rmse:0.41590\n",
      "[70]\ttrain-rmse:0.32553\tval-rmse:0.41617\n",
      "[71]\ttrain-rmse:0.32521\tval-rmse:0.41631\n",
      "[72]\ttrain-rmse:0.32467\tval-rmse:0.41636\n",
      "[73]\ttrain-rmse:0.32452\tval-rmse:0.41637\n",
      "[74]\ttrain-rmse:0.32355\tval-rmse:0.41642\n",
      "[75]\ttrain-rmse:0.32315\tval-rmse:0.41647\n",
      "[76]\ttrain-rmse:0.32239\tval-rmse:0.41665\n",
      "[77]\ttrain-rmse:0.32225\tval-rmse:0.41661\n",
      "[78]\ttrain-rmse:0.32084\tval-rmse:0.41655\n",
      "[79]\ttrain-rmse:0.32029\tval-rmse:0.41651\n",
      "[80]\ttrain-rmse:0.32012\tval-rmse:0.41654\n",
      "[81]\ttrain-rmse:0.31952\tval-rmse:0.41652\n",
      "[82]\ttrain-rmse:0.31909\tval-rmse:0.41644\n",
      "[83]\ttrain-rmse:0.31883\tval-rmse:0.41650\n",
      "[84]\ttrain-rmse:0.31863\tval-rmse:0.41668\n",
      "[85]\ttrain-rmse:0.31829\tval-rmse:0.41673\n",
      "[86]\ttrain-rmse:0.31818\tval-rmse:0.41673\n",
      "[87]\ttrain-rmse:0.31789\tval-rmse:0.41665\n",
      "[88]\ttrain-rmse:0.31761\tval-rmse:0.41669\n",
      "[89]\ttrain-rmse:0.31733\tval-rmse:0.41662\n",
      "[90]\ttrain-rmse:0.31718\tval-rmse:0.41654\n",
      "[91]\ttrain-rmse:0.31705\tval-rmse:0.41657\n",
      "[92]\ttrain-rmse:0.31683\tval-rmse:0.41661\n",
      "[93]\ttrain-rmse:0.31589\tval-rmse:0.41656\n",
      "[94]\ttrain-rmse:0.31524\tval-rmse:0.41653\n",
      "[95]\ttrain-rmse:0.31392\tval-rmse:0.41661\n",
      "[96]\ttrain-rmse:0.31367\tval-rmse:0.41682\n",
      "[97]\ttrain-rmse:0.31274\tval-rmse:0.41686\n",
      "[98]\ttrain-rmse:0.31250\tval-rmse:0.41687\n",
      "[99]\ttrain-rmse:0.31183\tval-rmse:0.41674\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "\n",
    "    names = list(feature_names)  # ensure it's a list\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=names)\n",
    "    dval   = xgb.DMatrix(X_val,   label=y_val,   feature_names=names)\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "    def run_xgb(eta):\n",
    "        params = {\n",
    "            'eta': eta,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 1,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'nthread': 8,\n",
    "            'seed': 1,\n",
    "            'verbosity': 0,\n",
    "        }\n",
    "        model = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist)\n",
    "        val_pred = model.predict(dval)\n",
    "        return rmse(y_val, val_pred)\n",
    "\n",
    "    rmse_03 = run_xgb(0.3)\n",
    "    rmse_01 = run_xgb(0.1)\n",
    "    (round(rmse_03, 3), round(rmse_01, 3)), ('0.3' if rmse_03 < rmse_01 else '0.1' if rmse_01 < rmse_03 else 'equal')\n",
    "except Exception as e:\n",
    "    print('xgboost not available or failed to run:', e)\n",
    "    rmse_03 = rmse_01 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175655c",
   "metadata": {},
   "source": [
    "## 10. Summary for submission\n",
    "This prints the exact values you need for the multiple?choice form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acf5ae36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_root_feature': {'full': 'vehicle_weight', 'base': 'vehicle_weight'},\n",
       " 'Q2_rmse_rf10': 0.46,\n",
       " 'Q3_last_new_best_n': 90,\n",
       " 'Q3_rmse_track': [(10, 0.46),\n",
       "  (20, 0.446),\n",
       "  (30, 0.44),\n",
       "  (40, 0.438),\n",
       "  (50, 0.437),\n",
       "  (60, 0.436),\n",
       "  (70, 0.436),\n",
       "  (80, 0.436),\n",
       "  (90, 0.435),\n",
       "  (100, 0.435),\n",
       "  (110, 0.435),\n",
       "  (120, 0.435),\n",
       "  (130, 0.435),\n",
       "  (140, 0.435),\n",
       "  (150, 0.435),\n",
       "  (160, 0.435),\n",
       "  (170, 0.435),\n",
       "  (180, 0.435),\n",
       "  (190, 0.435),\n",
       "  (200, 0.435)],\n",
       " 'Q4_mean_rmse': {10: 0.436, 15: 0.438, 20: 0.438, 25: 0.438},\n",
       " 'Q4_best_depth': 10,\n",
       " 'Q5_importances': {'vehicle_weight': 0.9599,\n",
       "  'horsepower': 0.0159,\n",
       "  'acceleration': 0.0114,\n",
       "  'engine_displacement': 0.0032},\n",
       " 'Q5_most_important': 'vehicle_weight'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {}\n",
    "try:\n",
    "    summary['Q1_root_feature'] = {'full': root_name, 'base': base_name}\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    summary['Q2_rmse_rf10'] = round(rmse_rf10, 3)\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    summary['Q3_last_new_best_n'] = last_new_best_n\n",
    "    summary['Q3_rmse_track'] = [(n, round(r,3)) for n, r in rmse_track]\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    summary['Q4_mean_rmse'] = {k: round(v, 3) for k, v in mean_rmse.items()}\n",
    "    summary['Q4_best_depth'] = min(mean_rmse, key=mean_rmse.get)\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    summary['Q5_importances'] = {k: round(v, 4) for k, v in subset.items()}\n",
    "    summary['Q5_most_important'] = max(subset, key=subset.get)\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    if rmse_03 is not None:\n",
    "        summary['Q6_xgb_rmse'] = {'eta_0.3': round(rmse_03, 3), 'eta_0.1': round(rmse_01, 3)}\n",
    "        summary['Q6_best'] = '0.3' if rmse_03 < rmse_01 else '0.1' if rmse_01 < rmse_03 else 'equal'\n",
    "except NameError:\n",
    "    pass\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
