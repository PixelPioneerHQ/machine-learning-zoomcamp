{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e456f9fc",
   "metadata": {},
   "source": [
    "# Module 3 ? Classification Homework (2025 cohort)\n",
    "\n",
    "Dataset: Bank Marketing style lead scoring ? target column `converted`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c6d94",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "We use Pandas/NumPy for data prep and scikit?learn for splitting, mutual information, encoding, and logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f764659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b3c85",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Data\n",
    "\n",
    "We load only once from the course URL. If you prefer a local copy, download the CSV to a `data/` folder and change `DATA_URL` accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b1eaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.00000</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.00000</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.00000</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.00000</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1    79450.00000   \n",
       "1  social_media      retail                         1    46992.00000   \n",
       "2        events  healthcare                         5    78796.00000   \n",
       "3      paid_ads      retail                         2    83843.00000   \n",
       "4      referral   education                         3    85012.00000   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4     0.94000          1  \n",
       "1          employed  south_america                  1     0.80000          0  \n",
       "2        unemployed      australia                  3     0.69000          1  \n",
       "3               NaN      australia                  1     0.87000          0  \n",
       "4     self_employed         europe                  3     0.62000          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_URL = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_URL)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5a193",
   "metadata": {},
   "source": [
    "## 3. Target and Feature Types\n",
    "\n",
    "- Target: `converted` (binary: 0/1)\n",
    "- We'll detect numeric vs categorical by dtype; then apply the homework's imputation rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e76d352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['number_of_courses_viewed',\n",
       "  'annual_income',\n",
       "  'interaction_count',\n",
       "  'lead_score'],\n",
       " ['lead_source', 'industry', 'employment_status', 'location'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'converted'\n",
    "\n",
    "# Separate features and target\n",
    "full_cols = df.columns.tolist()\n",
    "feature_cols = [c for c in full_cols if c != TARGET]\n",
    "\n",
    "# Infer types\n",
    "num_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in feature_cols if c not in num_cols]\n",
    "\n",
    "num_cols, cat_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6c089",
   "metadata": {},
   "source": [
    "## 4. Missing Values (Homework Data Preparation)\n",
    "\n",
    "- Categorical NaNs ? `'NA'`\n",
    "- Numerical NaNs ? `0.0`\n",
    "\n",
    "We keep a clean `df_clean` for downstream steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d517bf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Fill categorical with 'NA'\n",
    "for c in cat_cols:\n",
    "    df_clean[c] = df_clean[c].astype('object').fillna('NA')\n",
    "\n",
    "# Fill numeric with 0.0\n",
    "for c in num_cols:\n",
    "    df_clean[c] = df_clean[c].astype('float64').fillna(0.0)\n",
    "\n",
    "# Quick check remaining NAs\n",
    "na_check = df_clean[feature_cols].isna().sum().sum()\n",
    "na_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d98b3a",
   "metadata": {},
   "source": [
    "## 5. Question 1 ? Mode of `industry`\n",
    "\n",
    "We compute the mode of `industry` after imputation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f00bdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_industry = df_clean['industry'].mode(dropna=False).iloc[0]\n",
    "mode_industry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbdd34",
   "metadata": {},
   "source": [
    "## 6. Question 2 ? Correlation Matrix (Numeric Only)\n",
    "\n",
    "We compute a correlation matrix for numeric features and then report the correlation for the specified pairs:\n",
    "- `interaction_count` ? `lead_score`\n",
    "- `number_of_courses_viewed` ? `lead_score`\n",
    "- `number_of_courses_viewed` ? `interaction_count`\n",
    "- `annual_income` ? `lead_score`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0932328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('interaction_count', 'lead_score'): 0.009888182496913131,\n",
       " ('number_of_courses_viewed', 'lead_score'): 0.004878998354681276,\n",
       " ('number_of_courses_viewed', 'interaction_count'): 0.023565222882888037,\n",
       " ('annual_income', 'lead_score'): 0.015609546050139008}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_clean[num_cols].corr(numeric_only=True)\n",
    "\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'lead_score'),\n",
    "]\n",
    "\n",
    "pair_vals = {}\n",
    "for a, b in pairs:\n",
    "    if a in corr.index and b in corr.columns:\n",
    "        pair_vals[(a, b)] = float(abs(corr.loc[a, b]))\n",
    "    else:\n",
    "        pair_vals[(a, b)] = np.nan\n",
    "\n",
    "pair_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cb3ac3",
   "metadata": {},
   "source": [
    "## 7. Train/Val/Test Split (60/20/20)\n",
    "\n",
    "- Use `train_test_split` with `random_state=42`.\n",
    "- Ensure target is not in the features frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62ece856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 292, 293)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_clean[feature_cols].copy()\n",
    "y = df_clean[TARGET].astype('int64').values\n",
    "\n",
    "# First split train vs temp (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "# Split temp into val and test 50/50 ? each becomes 20% of total\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e709403",
   "metadata": {},
   "source": [
    "## 8. Question 3 ? Mutual Information of Categorical Features\n",
    "\n",
    "Compute mutual information on the training set only, round to 2 decimals, and report the largest among:\n",
    "- `industry`, `location`, `lead_source`, `employment_status`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f230ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'industry': 0.01,\n",
       " 'location': 0.0,\n",
       " 'lead_source': 0.03,\n",
       " 'employment_status': 0.01}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mutual_info_classif_series(x, y):\n",
    "    # x and y must be 1D label arrays\n",
    "    return mutual_info_score(x, y)\n",
    "\n",
    "mi_features = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "mi_scores = {}\n",
    "for c in mi_features:\n",
    "    if c in X_train.columns:\n",
    "        s = mutual_info_classif_series(X_train[c], y_train)\n",
    "        mi_scores[c] = round(float(s), 2)\n",
    "    else:\n",
    "        mi_scores[c] = np.nan\n",
    "\n",
    "mi_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94465b12",
   "metadata": {},
   "source": [
    "## 9. Question 4 ? Logistic Regression with One?Hot Encoding\n",
    "\n",
    "We one?hot encode categorical variables (training fit only), align columns for validation, and evaluate accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784a23c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6815068493150684, 0.68)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One?hot encode train\n",
    "X_train_enc = pd.get_dummies(X_train, columns=cat_cols, drop_first=False)\n",
    "\n",
    "# Apply same columns to val: get_dummies and align\n",
    "X_val_enc = pd.get_dummies(X_val, columns=cat_cols, drop_first=False)\n",
    "X_val_enc = X_val_enc.reindex(columns=X_train_enc.columns, fill_value=0)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_enc, y_train)\n",
    "val_pred = logreg.predict(X_val_enc)\n",
    "acc_val = accuracy_score(y_val, val_pred)\n",
    "acc_val, round(acc_val, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805599c7",
   "metadata": {},
   "source": [
    "## 10. Question 5 ? Simple Feature Elimination by Leaving?One?Out\n",
    "\n",
    "Train the baseline model (Q4), then for each original feature, remove it, re?fit, and measure ?accuracy = baseline ? without(feature).\n",
    "We report the smallest difference among the listed options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf3d6561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'industry': -0.006849315068493178,\n",
       " 'employment_status': 0.0,\n",
       " 'lead_score': 0.006849315068493067}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_acc = acc_val\n",
    "\n",
    "candidates = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "acc_drop = {}\n",
    "for feat in candidates:\n",
    "    cols_minus = [c for c in feature_cols if c != feat]\n",
    "\n",
    "    Xt = X_train[cols_minus]\n",
    "    Xv = X_val[cols_minus]\n",
    "\n",
    "    Xt_enc = pd.get_dummies(Xt, columns=[c for c in cols_minus if c in cat_cols], drop_first=False)\n",
    "    Xv_enc = pd.get_dummies(Xv, columns=[c for c in cols_minus if c in cat_cols], drop_first=False)\n",
    "    Xv_enc = Xv_enc.reindex(columns=Xt_enc.columns, fill_value=0)\n",
    "\n",
    "    m = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    m.fit(Xt_enc, y_train)\n",
    "    pred = m.predict(Xv_enc)\n",
    "    acc = accuracy_score(y_val, pred)\n",
    "\n",
    "    acc_drop[feat] = float(baseline_acc - acc)\n",
    "\n",
    "acc_drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6b48d",
   "metadata": {},
   "source": [
    "## 11. Question 6 ? Regularization Sweep\n",
    "\n",
    "Evaluate validation accuracy for `C` in `[0.01, 0.1, 1, 10, 100]` using the same encoded features as in Q4. Report the best accuracy (rounded to 3 decimals) and the smallest `C` achieving it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db382274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0.01: 0.688, 0.1: 0.682, 1: 0.682, 10: 0.682, 100: 0.682}, 0.01, 0.688)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_C = [0.01, 0.1, 1, 10, 100]\n",
    "acc_by_C = {}\n",
    "\n",
    "for C in grid_C:\n",
    "    m = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    m.fit(X_train_enc, y_train)\n",
    "    p = m.predict(X_val_enc)\n",
    "    acc = accuracy_score(y_val, p)\n",
    "    acc_by_C[C] = float(acc)\n",
    "\n",
    "acc_rounded = {k: round(v, 3) for k, v in acc_by_C.items()}\n",
    "best_acc = max(acc_by_C.values())\n",
    "best_C = min([C for C, a in acc_by_C.items() if abs(a - best_acc) < 1e-12])\n",
    "acc_rounded, best_C, round(best_acc, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b1e0e",
   "metadata": {},
   "source": [
    "## 12. Summary for Submission\n",
    "\n",
    "This cell prints all values needed for the multiple?choice form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2382f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_mode_industry': 'retail',\n",
       " 'Q2_pairwise_corr_abs': {('interaction_count',\n",
       "   'lead_score'): 0.009888182496913131,\n",
       "  ('number_of_courses_viewed', 'lead_score'): 0.004878998354681276,\n",
       "  ('number_of_courses_viewed', 'interaction_count'): 0.023565222882888037,\n",
       "  ('annual_income', 'lead_score'): 0.015609546050139008},\n",
       " 'Q3_mi_scores': {'industry': 0.01,\n",
       "  'location': 0.0,\n",
       "  'lead_source': 0.03,\n",
       "  'employment_status': 0.01},\n",
       " 'Q4_val_accuracy': 0.68,\n",
       " 'Q5_delta_accuracy_by_feature': {'industry': -0.006849315068493178,\n",
       "  'employment_status': 0.0,\n",
       "  'lead_score': 0.006849315068493067},\n",
       " 'Q6_best_C': 0.01,\n",
       " 'Q6_best_val_accuracy': 0.688}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    'Q1_mode_industry': str(mode_industry),\n",
    "    'Q2_pairwise_corr_abs': pair_vals,  # inspect to choose the largest\n",
    "    'Q3_mi_scores': mi_scores,\n",
    "    'Q4_val_accuracy': round(acc_val, 2),\n",
    "    'Q5_delta_accuracy_by_feature': acc_drop,\n",
    "    'Q6_best_C': best_C,\n",
    "    'Q6_best_val_accuracy': round(max(acc_by_C.values()), 3),\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04541a-6a23-4124-b4d5-a351039c8862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
