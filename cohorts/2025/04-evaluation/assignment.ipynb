{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc8f011",
   "metadata": {},
   "source": [
    "# Module 4 ? Evaluation Homework (2025 cohort, updated)\n",
    "\n",
    "Lead scoring dataset (`course_lead_scoring.csv`) with target `converted`.\n",
    "This notebook mirrors the new homework text exactly and prints the values you need to map to the multiple?choice options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2e9d6",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a03e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af8a59",
   "metadata": {},
   "source": [
    "## 2. Load dataset and basic prep\n",
    "\n",
    "- Source: https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
    "- Target: `converted` (already numeric).\n",
    "- Imputation per brief: categorical ? 'NA'; numerical ? 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc5dac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['number_of_courses_viewed',\n",
       "  'annual_income',\n",
       "  'interaction_count',\n",
       "  'lead_score'],\n",
       " ['lead_source', 'industry', 'employment_status', 'location'],\n",
       " converted\n",
       " 1   0.619015\n",
       " 0   0.380985\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "\n",
    "df_raw = pd.read_csv(URL)\n",
    "\n",
    "TARGET = 'converted'\n",
    "feature_cols = [c for c in df_raw.columns if c != TARGET]\n",
    "\n",
    "num_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(df_raw[c])]\n",
    "cat_cols = [c for c in feature_cols if c not in num_cols]\n",
    "\n",
    "# Apply imputation rules\n",
    "df = df_raw.copy()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].astype('object').fillna('NA')\n",
    "for c in num_cols:\n",
    "    df[c] = df[c].astype('float64').fillna(0.0)\n",
    "\n",
    "num_cols, cat_cols, df[TARGET].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7621c13",
   "metadata": {},
   "source": [
    "## 3. Split train/val/test (60/20/20, random_state=1)\n",
    "We keep class balance via stratify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a18a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 292, 293)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET].astype('int64').values\n",
    "\n",
    "# non-stratified, random_state=1\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=1\n",
    ")\n",
    "\n",
    "len(X_train), len(X_val), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3cedeb",
   "metadata": {},
   "source": [
    "## 4. Q1 ? ROC AUC feature importance (numeric only)\n",
    "Treat each numeric feature as a score vs `converted` on the training set; if AUC < 0.5, negate the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90f4663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'number_of_courses_viewed': 0.7652439024390244,\n",
       "  'annual_income': 0.5446354552990968,\n",
       "  'interaction_count': 0.7271914132379249,\n",
       "  'lead_score': 0.6111168681007025},\n",
       " {'lead_score': 0.6111168681007025,\n",
       "  'number_of_courses_viewed': 0.7652439024390244,\n",
       "  'interaction_count': 0.7271914132379249,\n",
       "  'annual_income': 0.5446354552990968})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def auc_for_numeric(series, y_true):\n",
    "    s = series.values.astype('float64')\n",
    "    auc = roc_auc_score(y_true, s)\n",
    "    if auc < 0.5:\n",
    "        auc = roc_auc_score(y_true, -s)\n",
    "    return float(auc)\n",
    "\n",
    "aucs = {c: auc_for_numeric(X_train[c], y_train) for c in num_cols}\n",
    "\n",
    "# Show only the four asked\n",
    "asked = ['lead_score','number_of_courses_viewed','interaction_count','annual_income']\n",
    "aucs_filtered = {k: aucs.get(k, np.nan) for k in asked}\n",
    "aucs, aucs_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda3f43",
   "metadata": {},
   "source": [
    "## 5. Q2 ? Logistic Regression (DictVectorizer OHE)\n",
    "Fit on train, evaluate AUC on validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879df375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7944791666666666, 0.794)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dicts = X_train.to_dict(orient='records')\n",
    "val_dicts = X_val.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train_dv = dv.fit_transform(train_dicts)\n",
    "X_val_dv = dv.transform(val_dicts)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=1)\n",
    "model.fit(X_train_dv, y_train)\n",
    "val_scores = model.predict_proba(X_val_dv)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_scores)\n",
    "val_auc, round(val_auc, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff3fb1",
   "metadata": {},
   "source": [
    "## 6. Q3 ? Precision and Recall vs threshold\n",
    "We scan thresholds 0.00?1.00 step 0.01 and find where precision and recall are equal (closest intersection).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c23205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59, 0.8072916666666666, 0.8072916666666666)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, 101)\n",
    "precisions, recalls = [], []\n",
    "for t in thresholds:\n",
    "    y_bin = (val_scores >= t).astype('int64')\n",
    "    p = precision_score(y_val, y_bin, zero_division=0)\n",
    "    r = recall_score(y_val, y_bin)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "idx = int(np.argmin(np.abs(np.array(precisions) - np.array(recalls))))\n",
    "th_intersection = float(thresholds[idx])\n",
    "th_intersection, precisions[idx], recalls[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea61636",
   "metadata": {},
   "source": [
    "## 7. Q4 ? F1 vs threshold\n",
    "Compute F1 across thresholds and pick the max.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad35b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47000000000000003, 0.8484848484848485)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(p, r):\n",
    "    return 0.0 if (p + r) == 0 else 2 * p * r / (p + r)\n",
    "\n",
    "f1s = [f1(p, r) for p, r in zip(precisions, recalls)]\n",
    "idx_f1 = int(np.argmax(f1s))\n",
    "th_best_f1 = float(thresholds[idx_f1])\n",
    "max_f1 = float(f1s[idx_f1])\n",
    "th_best_f1, max_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944cc8d6",
   "metadata": {},
   "source": [
    "## 8. Q5 ? 5?Fold CV (AUC std)\n",
    "We build `df_full_train = train ? val` and compute AUC on 5 folds; report standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f73e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.806680393502631,\n",
       "  0.8067501795260512,\n",
       "  0.8648193508879363,\n",
       "  0.8334380892520429,\n",
       "  0.8153846153846154],\n",
       " 0.021986552473681004,\n",
       " 0.022)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train = pd.concat([\n",
    "    X_train.assign(converted=y_train),\n",
    "    X_val.assign(converted=y_val)\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "features = feature_cols\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "auc_scores = []\n",
    "\n",
    "for tr_idx, va_idx in kf.split(df_full_train):\n",
    "    df_tr = df_full_train.iloc[tr_idx]\n",
    "    df_va = df_full_train.iloc[va_idx]\n",
    "\n",
    "    X_tr = df_tr[features]\n",
    "    y_tr = df_tr[TARGET].values\n",
    "    X_va = df_va[features]\n",
    "    y_va = df_va[TARGET].values\n",
    "\n",
    "    dv_cv = DictVectorizer(sparse=False)\n",
    "    X_tr_dv = dv_cv.fit_transform(X_tr.to_dict(orient='records'))\n",
    "    X_va_dv = dv_cv.transform(X_va.to_dict(orient='records'))\n",
    "\n",
    "    m = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=1)\n",
    "    m.fit(X_tr_dv, y_tr)\n",
    "    p = m.predict_proba(X_va_dv)[:, 1]\n",
    "    auc_scores.append(roc_auc_score(y_va, p))\n",
    "\n",
    "auc_std = float(np.std(auc_scores))\n",
    "auc_scores, auc_std, round(auc_std, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57de22d",
   "metadata": {},
   "source": [
    "## 9. Q6 ? Hyperparameter Tuning (5?Fold CV)\n",
    "Try C in `[1e-6, 1e-3, 1]`; compute mean/std AUC and select best C per rules (best mean ? smallest std ? smallest C).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0938a89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1e-06: {'mean': 0.543, 'std': 0.025},\n",
       "  0.001: {'mean': 0.864, 'std': 0.014},\n",
       "  1: {'mean': 0.825, 'std': 0.022}},\n",
       " 0.001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_grid = [0.000001, 0.001, 1]\n",
    "results = {}\n",
    "\n",
    "for C in C_grid:\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in kf.split(df_full_train):\n",
    "        df_tr = df_full_train.iloc[tr_idx]\n",
    "        df_va = df_full_train.iloc[va_idx]\n",
    "\n",
    "        X_tr = df_tr[features]\n",
    "        y_tr = df_tr[TARGET].values\n",
    "        X_va = df_va[features]\n",
    "        y_va = df_va[TARGET].values\n",
    "\n",
    "        dv_cv = DictVectorizer(sparse=False)\n",
    "        X_tr_dv = dv_cv.fit_transform(X_tr.to_dict(orient='records'))\n",
    "        X_va_dv = dv_cv.transform(X_va.to_dict(orient='records'))\n",
    "\n",
    "        m = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=1)\n",
    "        m.fit(X_tr_dv, y_tr)\n",
    "        p = m.predict_proba(X_va_dv)[:, 1]\n",
    "        scores.append(roc_auc_score(y_va, p))\n",
    "\n",
    "    results[C] = {\n",
    "        'mean': round(float(np.mean(scores)), 3),\n",
    "        'std': round(float(np.std(scores)), 3)\n",
    "    }\n",
    "\n",
    "best_mean = max(v['mean'] for v in results.values())\n",
    "cands = [C for C, v in results.items() if v['mean'] == best_mean]\n",
    "if len(cands) > 1:\n",
    "    best_std = min(results[C]['std'] for C in cands)\n",
    "    cands = [C for C in cands if results[C]['std'] == best_std]\n",
    "\n",
    "best_C = min(cands)\n",
    "results, best_C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df45b3",
   "metadata": {},
   "source": [
    "## 10. Summary for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f98f35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_numeric_auc_filtered': {'lead_score': 0.6111168681007025,\n",
       "  'number_of_courses_viewed': 0.7652439024390244,\n",
       "  'interaction_count': 0.7271914132379249,\n",
       "  'annual_income': 0.5446354552990968},\n",
       " 'Q2_val_auc': 0.794,\n",
       " 'Q3_threshold_intersection': 0.59,\n",
       " 'Q4_threshold_best_f1': 0.47000000000000003,\n",
       " 'Q5_auc_std_5fold': 0.022,\n",
       " 'Q6_results': {1e-06: {'mean': 0.543, 'std': 0.025},\n",
       "  0.001: {'mean': 0.864, 'std': 0.014},\n",
       "  1: {'mean': 0.825, 'std': 0.022}},\n",
       " 'Q6_best_C': 0.001}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    'Q1_numeric_auc_filtered': aucs_filtered,\n",
    "    'Q2_val_auc': round(val_auc, 3),\n",
    "    'Q3_threshold_intersection': th_intersection,\n",
    "    'Q4_threshold_best_f1': th_best_f1,\n",
    "    'Q5_auc_std_5fold': round(auc_std, 3),\n",
    "    'Q6_results': results,\n",
    "    'Q6_best_C': best_C,\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5053a53-2d25-45e2-94c6-88b158410654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
